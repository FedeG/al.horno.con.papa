# ü§ñ IA Local con Ollama - Roadmap de Implementaci√≥n

> **Estado:** üìã Planeado | **Prioridad:** Alta | **Estimaci√≥n:** 2-3 semanas

Esta feature agregar√° capacidades de procesamiento inteligente usando modelos de lenguaje (LLM) 100% locales mediante Ollama, sin necesidad de APIs externas ni costos recurrentes.

---

## üéØ Objetivos

1. **Enriquecer recetas existentes** con datos generados por IA
2. **Optimizar sistema de tags** para mejores relaciones entre recetas
3. **Mejorar b√∫squeda** con capacidades sem√°nticas
4. **Generar contenido** autom√°tico para redes sociales

---

## üöÄ Instalaci√≥n de Ollama en Ubuntu

### Paso 1: Instalar Ollama

Abre la terminal y ejecuta el instalador oficial:

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

Verifica la instalaci√≥n:

```bash
ollama --version
```

### Paso 2: Descargar los Modelos

Para este proyecto, utilizaremos estos modelos seg√∫n la necesidad:

```bash
ollama pull llama3.2    # El m√°s r√°pido (ideal para GTX 1050 - 2GB VRAM)
ollama pull llama3      # El m√°s equilibrado y potente (8B par√°metros)
ollama pull mistral     # Excelente para razonamiento y cocina
```

**Tiempo estimado de descarga:** 10-30 minutos dependiendo de tu conexi√≥n.

### Paso 3: Instalar Dependencias Python

```bash
cd scripts
source venv/bin/activate  # o crear el venv si no existe
pip install ollama
```

---

## üìä Comparativa de Modelos

| Feature | Llama 3.2 (3B) | Llama 3 (8B) | Mistral (7B) |
|---------|----------------|--------------|--------------|
| Peso en Disco | ~2.0 GB | ~4.7 GB | ~4.1 GB |
| Uso de VRAM | Muy bajo (2GB) | Medio (8GB) | Medio (8GB) |
| Velocidad | ‚ö° Instant√°nea | üê¢ Moderada (usa RAM) | üê¢ Moderada (usa RAM) |
| Ideal para | Clasificaci√≥n r√°pida | Tareas complejas | Creatividad/Estructura |
| **Recomendado para este proyecto** | ‚úÖ S√≠ (GPU 2GB) | ‚ö†Ô∏è Con 8GB+ RAM | ‚ö†Ô∏è Con 8GB+ RAM |

**Recomendaci√≥n:** Usa `llama3.2` como modelo principal para desarrollo. Los modelos de 7B-8B son m√°s potentes pero requerir√°n usar RAM del sistema si tu GPU tiene solo 2GB VRAM.

---

## üó∫Ô∏è Roadmap de Implementaci√≥n

### Fase 1: Setup (Semana 1)

- [x] Documentar arquitectura de IA
- [x] Instalar Ollama en servidor de desarrollo
- [x] Descargar y probar modelos (llama3.2, llama3)
- [ ] Crear estructura de carpetas `scripts/ai/`
- [ ] Testear integraci√≥n b√°sica Python + Ollama

### Fase 2: Optimizador de Tags (Semana 2)

- [ ] Implementar an√°lisis de tags existentes
- [ ] Crear generador de sistema est√°ndar de tags
- [ ] Implementar reglas de relaci√≥n autom√°ticas
- [ ] Procesar recetas con contexto completo
- [ ] Testear con 50 recetas
- [ ] Ejecutar sobre las ~500 recetas completas
- [ ] Actualizar frontend para usar nuevos tags

### Fase 3: Enriquecedor de Recetas (Semana 3)

- [ ] Implementar estandarizador de ingredientes
- [ ] Crear clasificador de dificultad
- [ ] Generar estimaciones de tiempo
- [ ] Agregar sugerencias de maridaje
- [ ] Integrar con pipeline de actualizaci√≥n

### Fase 4: Features Avanzadas (Futuro)

- [ ] B√∫squeda sem√°ntica en frontend
- [ ] Analizador de posts de Instagram
- [ ] Sistema de recomendaciones personalizado
- [ ] Generador de descripciones para redes sociales

---

## ‚öôÔ∏è Integraci√≥n con el Proyecto

### Estructura de Archivos

```
scripts/
‚îú‚îÄ‚îÄ ai/                          # üÜï Nueva carpeta para scripts de IA
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ process_recipes.py       # Procesador b√°sico de recetas
‚îÇ   ‚îú‚îÄ‚îÄ optimize_tags.py         # Optimizador de tags con contexto
‚îÇ   ‚îú‚îÄ‚îÄ search_recipes.py        # B√∫squeda sem√°ntica
‚îÇ   ‚îî‚îÄ‚îÄ analyze_posts.py         # Analizador de Instagram
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ instagram_service.py     # Existente
‚îÇ   ‚îú‚îÄ‚îÄ parser_service.py        # Existente
‚îÇ   ‚îî‚îÄ‚îÄ ai_service.py            # üÜï Servicio compartido de IA
‚îú‚îÄ‚îÄ main.py                      # Script principal de Instagram
‚îú‚îÄ‚îÄ ia_main.py                   # üÜï Script principal de IA
‚îú‚îÄ‚îÄ run_ia.sh                    # üÜï Script bash para ejecutar IA
‚îú‚îÄ‚îÄ local_update.py              # Actualizar para incluir IA (opcional)
‚îî‚îÄ‚îÄ requirements.txt             # Agregar: ollama
```

### üöÄ Scripts Principales

#### 1. Script de Python: [`ia_main.py`](scripts/ia_main.py)

Script principal para procesar recetas con IA. Soporta modo dry-run y procesamiento por lotes.

**Caracter√≠sticas:**
- ‚úÖ Modo `--dry-run` para visualizar sin guardar
- ‚úÖ Par√°metro `--recipes N` para limitar cantidad
- ‚úÖ **Carga contexto global autom√°ticamente** (todas las recetas, tags, categor√≠as)
- ‚úÖ Opci√≥n `--no-context` para desactivar contexto (m√°s r√°pido)
- ‚úÖ Selecci√≥n de modelo con `--model`
- ‚úÖ Rutas personalizables de entrada/salida
- ‚úÖ Verificaci√≥n autom√°tica de modelos disponibles

**Uso:**
```bash
cd scripts

# Procesar 3 recetas en modo dry-run (CON contexto global)
python ia_main.py --recipes 3 --dry-run

# Procesar 10 recetas y guardar (contexto activado por defecto)
python ia_main.py --recipes 10

# Procesar sin contexto global (m√°s r√°pido, menos consistente)
python ia_main.py --recipes 5 --no-context

# Procesar todas con modelo espec√≠fico
python ia_main.py --model llama3

# Ver ayuda completa
python ia_main.py --help
```

**¬øQu√© es el contexto global?**

Antes de procesar las N recetas solicitadas, el script:
1. Carga **todas** las recetas del sistema
2. Extrae tags existentes, categor√≠as, y patrones
3. Genera un contexto informativo con estad√≠sticas
4. Env√≠a ese contexto a Ollama junto con cada receta a procesar

**Beneficios:**
- üéØ **Mayor consistencia** en tags y categor√≠as
- üîó **Mejor coherencia** con recetas existentes
- üìä **Reutiliza nomenclatura** establecida
- üé® **Mantiene estilo** uniforme en toda la base de datos

**Ejemplo de contexto generado:**
```
CONTEXTO GLOBAL DE LA BASE DE DATOS DE RECETAS:

Total de recetas en el sistema: 487

Tags m√°s utilizados actualmente (formato: tag ‚Üí cantidad):
  ‚Ä¢ pasta ‚Üí 45
  ‚Ä¢ vegetariano ‚Üí 38
  ‚Ä¢ r√°pido ‚Üí 35
  ‚Ä¢ italiano ‚Üí 28
  ‚Ä¢ postres ‚Üí 25
  ...

Muestra de recetas existentes:
  ‚Ä¢ Pasta Carbonara
  ‚Ä¢ Tarta de Manzana
  ‚Ä¢ Ensalada C√©sar
  ...

Categor√≠as de cocina encontradas: italiana, mexicana, argentina, asi√°tica
Niveles de dificultad utilizados: F√°cil, Media, Dif√≠cil
```

Este contexto se env√≠a a la IA antes de procesar cada receta, permitiendo que mantenga consistencia.

#### 2. Script Bash: [`run_ia.sh`](scripts/run_ia.sh)

Script automatizado que gestiona todo el flujo de trabajo:

**Funcionalidades:**
- ‚úÖ Verifica instalaci√≥n de Ollama
- ‚úÖ Inicia Ollama autom√°ticamente si no est√° corriendo
- ‚úÖ Descarga el modelo si no existe
- ‚úÖ Activa entorno virtual de Python
- ‚úÖ Instala dependencias faltantes
- ‚úÖ Ejecuta `ia_main.py` con par√°metros configurables
- ‚úÖ Opci√≥n para detener Ollama al finalizar

**Uso:**
```bash
cd scripts

# Ejecutar script completo (incluye dry-run con 3 recetas)
./run_ia.sh

# Para modificar par√°metros, edita el script o ejecuta ia_main.py directamente
```

**Configuraci√≥n en el script:**
```bash
# Dentro de run_ia.sh, l√≠nea ~17:
OLLAMA_AUTO_STOP=false  # Cambiar a true para detener Ollama autom√°ticamente

# Dentro de run_ia.sh, √∫ltima l√≠nea del paso 6:
python3 ia_main.py --dry-run --recipes 3  # Modificar par√°metros aqu√≠
```

**Servicio Compartido de IA:** [`scripts/services/ai_service.py`](scripts/services/ai_service.py)

Este servicio proporciona funciones comunes para interactuar con Ollama. Incluye:

- Generaci√≥n de respuestas con control de temperatura
- Extracci√≥n autom√°tica de JSON de respuestas
- Verificaci√≥n de modelos disponibles
- Gesti√≥n de errores

**Uso del servicio:**

```python
from services.ai_service import crear_servicio_ia

# Crear instancia del servicio
ai = crear_servicio_ia('llama3.2')

# Generar respuesta JSON
resultado = ai.generar_json(
    prompt="Analiza esta receta...",
    temperatura=0.3
)
```

### Flujo de Trabajo

**Flujo Manual (paso a paso):**
```
Instagram ‚Üí main.py ‚Üí recipes.json
              ‚Üì
         local_update.py (normaliza tags b√°sicos)
              ‚Üì
         ia_main.py (enriquece con IA)
              ‚Üì
         recipes_enriquecidas.json ‚Üí Frontend
```

**Flujo Automatizado (con bash):**
```
./run_ia.sh
    ‚Üì
 Verifica/Inicia Ollama
    ‚Üì
 Ejecuta ia_main.py
    ‚Üì
 Muestra resultados
```

---

## üìã Features a Implementar

### 1. üè∑Ô∏è Optimizador de Tags (Prioridad Alta)

**Objetivo:** Analizar todas las recetas con contexto completo y optimizar tags para mejorar relaciones entre recetas.

**Script:** `scripts/ai/optimize_tags.py`

**Funcionalidades:**

- Analiza tags existentes y detecta redundancias
- Genera sistema est√°ndar de 20-30 tags consistentes
- Crea reglas de relaci√≥n autom√°ticas
- Sugiere tags optimizados por receta
- Identifica recetas similares para relacionar

**Integraci√≥n:**

- Se ejecuta sobre `src/data/recipes.json`
- Genera `src/data/recipes_tags_optimizados.json`
- Compatible con sistema actual de tags

### 2. üçù Enriquecedor de Recetas (Prioridad Media)

**Objetivo:** Agregar campos adicionales a recetas existentes.

**Script:** `scripts/ai/enrich_recipes.py`

**Funcionalidades:**

- Estandariza ingredientes (cantidad + unidad + ingrediente)
- Genera tags de salud (vegano, sin gluten, etc)
- Estima dificultad (F√°cil/Media/Dif√≠cil)
- Calcula tiempo de preparaci√≥n
- Sugiere maridajes
- Categoriza tipo de cocina (italiana, mexicana, etc)

**Output adicional:**

```json
{
  "name": "Pasta al Pesto",
  "ingredientes_estandarizados": ["400g pasta", "50g albahaca"],
  "tags_salud": ["vegetariano", "rico en prote√≠na"],
  "dificultad": "F√°cil",
  "tiempo_preparacion": "20",
  "sugerencia_maridaje": "Vino blanco italiano",
  "categoria_cocina": "italiana"
}
```

### 3. üì± Analizador de Posts de Instagram (Prioridad Baja)

**Objetivo:** Analizar captions de Instagram para generar insights.

**Script:** `scripts/ai/analyze_posts.py`

**Funcionalidades:**

- Detecta sentimiento del post
- Identifica call-to-action
- Sugiere hashtags optimizados
- Genera resumen corto
- Identifica temas principales

### 4. üîç B√∫squeda Sem√°ntica (Prioridad Media-Alta)

**Objetivo:** Permitir b√∫squedas en lenguaje natural.

**Script:** `scripts/ai/semantic_search.py`

**Ejemplos de b√∫squeda:**

- "Cena r√°pida sin gluten"
- "Postre vegano f√°cil para ni√±os"
- "Algo con pollo para el almuerzo"

**Integraci√≥n frontend:**

- Nuevo endpoint en `src/utils/index.js`
- Compatible con SearchBar existente
- Resultados ordenados por relevancia

---

## üêç Scripts Implementados

### A. Procesador B√°sico de Recetas

**Archivo:** [`scripts/ai/process_recipes.py`](scripts/ai/process_recipes.py)

Este script enriquece recetas individuales con datos generados por IA.

**Ejecuci√≥n:**

```bash
cd scripts
python -m ai.process_recipes
```

**Ejemplo de salida:**

```json
{
  "name": "Pasta al Pesto",
  "ingredients": "pasta, albahaca, ajo, pi√±ones, queso parmesano",
  "ingredientes_estandarizados": [
    "400g pasta",
    "50g albahaca fresca",
    "2 dientes ajo",
    "30g pi√±ones",
    "50g queso parmesano"
  ],
  "tags_salud": ["vegetariano", "rico en prote√≠na"],
  "dificultad": "F√°cil",
  "tiempo_preparacion": "20",
  "sugerencia_maridaje": "Vino blanco italiano (Pinot Grigio)",
  "categoria_cocina": "italiana"
}
```

### B. Procesador de Posts de Instagram (Engagement)

**Archivo:** [`scripts/ai/analyze_posts.py`](scripts/ai/analyze_posts.py)

Si tienes posts de IG gen√©ricos, usa este script para extraer informaci√≥n de marketing.

**Ejecuci√≥n:**

```bash
cd scripts
python -m ai.analyze_posts
```

### C. Optimizador de Tags para Relacionar Recetas

**Archivo:** [`scripts/ai/optimize_tags.py`](scripts/ai/optimize_tags.py)

Este script analiza todas tus recetas con contexto completo y sugiere tags optimizados para mejorar las relaciones entre recetas y la b√∫squeda.

**Ejecuci√≥n:**

```bash
cd scripts
python -m ai.optimize_tags
```

**‚ö†Ô∏è IMPORTANTE:** Este proceso puede tardar 10-20 minutos para 500 recetas. Usa `llama3` (8B) para mejor an√°lisis, o `llama3.2` si tienes poca VRAM.

**Funcionalidades:**

- Analiza tags existentes y detecta redundancias
- Genera sistema est√°ndar de 20-30 tags consistentes
- Crea reglas de relaci√≥n autom√°ticas
- Sugiere tags optimizados por receta
- Identifica recetas similares para relacionar

Ver c√≥digo completo en [`scripts/ai/optimize_tags.py`](scripts/ai/optimize_tags.py).

1. **An√°lisis Global**: La IA recibe todas las recetas y analiza:
   - Qu√© tags existen actualmente
   - Cu√°les son redundantes o inconsistentes
   - Qu√© tags nuevos deber√≠an agregarse
   - Crea un sistema est√°ndar de tags

2. **Reglas de Relaci√≥n**: Genera reglas autom√°ticas como:

   ```json
   {
     "si_tiene": "pasta",
     "agregar": ["italiano", "carbohidratos", "comfort food"]
   }
   ```

3. **Optimizaci√≥n Individual**: Cada receta se procesa con:
   - El contexto del sistema est√°ndar de tags
   - Reglas autom√°ticas aplicadas
   - Sugerencias de recetas relacionadas

**Ejemplo de resultado:**

```json
{
  "name": "Pasta Carbonara",
  "tags_originales": ["rapido", "italiano", "pasta"],
  "tags_optimizados": [
    "italiano",
    "pasta",
    "comfort food",
    "rico en prote√≠na",
    "cena",
    "tradicional"
  ],
  "tags_relacionados": [
    "Pasta al Pesto",
    "Spaghetti Bolognese",
    "Risotto de Hongos"
  ],
  "razon_optimizacion": "Agregados 'comfort food' y 'cena' para mejor categorizaci√≥n. Estandarizado 'rapido' a sistema uniforme."
}
```

**Uso del resultado para b√∫squedas:**

Una vez optimizados los tags, tu buscador puede:

- Encontrar recetas relacionadas f√°cilmente
- Sugerir "Si te gust√≥ X, prueba Y"
- Filtrar por categor√≠as consistentes
- Buscar por ocasi√≥n (cena, almuerzo, postre)

## üõ† 4. Gesti√≥n de Recursos en Ubuntu

Dado que tienes una GTX 1050 (2GB VRAM) y 24GB de RAM, aqu√≠ unos tips vitales:

### Monitoreo en Tiempo Real

Abre una terminal y usa:

```bash
watch -n 1 nvidia-smi
```

Esto te mostrar√° cada segundo:

- Temperatura de la GPU
- Uso de VRAM
- Procesos activos usando la GPU

### Liberar Memoria

Ollama mantiene el modelo cargado en memoria por **5 minutos** despu√©s del √∫ltimo uso. Si necesitas la RAM/VRAM para otra cosa:

```bash
# Detener un modelo espec√≠fico
ollama stop llama3.2

# O reiniciar el servicio completamente
sudo systemctl restart ollama
```

### Optimizaci√≥n para GTX 1050

Dado que tu GPU tiene solo 2GB de VRAM:

```bash
# Configurar Ollama para usar m√°s RAM del sistema
export OLLAMA_MAX_LOADED_MODELS=1
export OLLAMA_NUM_PARALLEL=1

# Reiniciar ollama con estas variables
sudo systemctl restart ollama
```

### Uso de Swap

Con 24GB de RAM est√°s bien, pero si procesas las 500 recetas de un tir√≥n con Llama 3 (8B):

1. Cierra Chrome/Firefox con muchas pesta√±as
2. Cierra editores de imagen/video
3. Monitorea con `htop` el uso de RAM

```bash
# Instalar htop si no lo tienes
sudo apt install htop

# Ejecutar
htop
```

## üí° 5. Detalles Importantes

### Control de Temperatura

Si quieres que la IA sea muy precisa y no invente datos:

```python
options={'temperature': 0}    # Muy preciso, nada de creatividad
options={'temperature': 0.3}  # Balance recomendado para recetas
options={'temperature': 0.7}  # M√°s creativo para descripciones
```

### Formato de Salida

Los modelos a veces escriben texto adicional como "Aqu√≠ tienes el JSON:". El script incluye limpieza autom√°tica:

```python
start = clean_res.find("{")
end = clean_res.rfind("}") + 1
data = json.loads(clean_res[start:end])
```

### Privacidad Total

‚úÖ Nada de lo que proceses sale de tu computadora  
‚úÖ Ideal para datos privados o de clientes  
‚úÖ No requiere internet despu√©s de descargar los modelos  
‚úÖ Sin cuotas ni l√≠mites de API  

### Procesamiento por Lotes

Para las 500 recetas, considera procesar en lotes:

```python
def procesar_por_lotes(archivo_entrada, archivo_salida, tama√±o_lote=50):
    """Procesa recetas en lotes para mejor gesti√≥n de memoria"""
    with open(archivo_entrada, 'r', encoding='utf-8') as f:
        todas_recetas = json.load(f)
    
    total_recetas = len(todas_recetas)
    resultados = []
    
    for i in range(0, total_recetas, tama√±o_lote):
        lote = todas_recetas[i:i+tama√±o_lote]
        print(f"\nüì¶ Procesando lote {i//tama√±o_lote + 1}/{(total_recetas-1)//tama√±o_lote + 1}")
        
        # Procesa el lote
        for receta in lote:
            # ... tu l√≥gica de procesamiento
            pass
        
        # Guarda progreso intermedio
        with open(f'temp_lote_{i}.json', 'w', encoding='utf-8') as f:
            json.dump(resultados, f, indent=2, ensure_ascii=False)
    
    # Guarda resultado final
    with open(archivo_salida, 'w', encoding='utf-8') as f:
        json.dump(resultados, f, indent=2, ensure_ascii=False)
```

## üîç 6. Buscador de Recetas con IA

**Archivo:** [`scripts/ai/search_recipes.py`](scripts/ai/search_recipes.py)

Ahora que tienes `tags_salud` y categor√≠as, puedes crear un buscador inteligente.

**Ejecuci√≥n:**

```bash
cd scripts
python -m ai.search_recipes
```

**Ejemplos de b√∫squeda en lenguaje natural:**

- "Cena r√°pida sin gluten"
- "Postre vegano f√°cil para ni√±os"
- "Algo con pollo para el almuerzo"

Ver c√≥digo completo en [`scripts/ai/search_recipes.py`](scripts/ai/search_recipes.py).

## üö® 7. Troubleshooting

### Error: "Ollama not found"

```bash
# Verificar si est√° instalado
which ollama

# Si no est√°, reinstalar
curl -fsSL https://ollama.com/install.sh | sh
```

### Error: "Failed to load model"

```bash
# Verificar modelos descargados
ollama list

# Descargar el modelo necesario
ollama pull llama3.2
```

### La GPU no se usa (solo CPU)

```bash
# Verificar drivers NVIDIA
nvidia-smi

# Si no funciona, instalar drivers:
sudo ubuntu-drivers autoinstall
sudo reboot
```

### Proceso muy lento

1. **Usa modelo m√°s peque√±o:** Cambia a `llama3.2` (3B)
2. **Reduce el contexto:** Limita `num_predict` a 300-400 tokens
3. **Procesa en lotes m√°s peque√±os:** 10-20 recetas por vez

### Out of Memory

```bash
# Limpiar memoria GPU
sudo systemctl restart ollama

# Monitorear uso
watch -n 1 'free -h && nvidia-smi'
```

## üìà 8. M√©tricas de √âxito

### KPIs del Proyecto

Una vez implementado, mediremos el √©xito con:

- **Consistencia de Tags:** Reducir tags √∫nicos de ~200 a ~30 est√°ndar
- **Calidad de Relaciones:** Cada receta debe tener 3-5 recetas relacionadas relevantes
- **Cobertura de Datos:** 100% de recetas con todos los campos enriquecidos
- **Tiempo de Procesamiento:** < 30 minutos para 500 recetas
- **Uso de Recursos:** Funcionar en GPU de 2GB VRAM

### Antes vs Despu√©s

| M√©trica | Antes | Despu√©s (Objetivo) |
|---------|-------|-------------------|
| Tags √∫nicos | ~200 | ~30 est√°ndar |
| Recetas con ingredientes estandarizados | 0% | 100% |
| Recetas con dificultad | 0% | 100% |
| Recetas con tiempo estimado | 0% | 100% |
| Recetas relacionadas por receta | 0 | 3-5 relevantes |

---

## üîÆ 9. Futuras Expansiones

Ideas adicionales una vez consolidado el sistema b√°sico:

1. **üåê API de B√∫squeda Sem√°ntica:**
   - Endpoint REST para b√∫squeda en lenguaje natural
   - Integraci√≥n con frontend React
   - Cache de embeddings para mejor performance

2. **üìä Dashboard de Analytics:**
   - Visualizaci√≥n de tags m√°s populares
   - Gr√°ficos de distribuci√≥n de dificultad
   - Mapa de relaciones entre recetas

3. **ü§ñ Generador de Contenido:**
   - Crear posts para Instagram autom√°ticamente
   - Generar descripciones atractivas
   - Sugerir hashtags optimizados

4. **üîÑ Pipeline Autom√°tico:**
   - Integrar IA en `main.py`
   - Enriquecer recetas al momento de scrapear
   - Deploy autom√°tico de cambios

5. **üé® Generaci√≥n de Im√°genes:**
   - Integrar Stable Diffusion local
   - Generar im√°genes para recetas sin foto
   - Crear variaciones visuales

---

## üìö 10. Recursos y Referencias

### Documentaci√≥n T√©cnica

- **Ollama Docs:** <https://github.com/ollama/ollama/blob/main/docs/api.md>
- **Ollama Python Library:** <https://github.com/ollama/ollama-python>
- **Modelos disponibles:** <https://ollama.com/library>

### Comunidad y Soporte

- **Ollama Discord:** <https://discord.gg/ollama>
- **Ubuntu AI Community:** <https://discourse.ubuntu.com/>
- **Llama Index (para RAG):** <https://www.llamaindex.ai/>

### Tutoriales Relacionados

- Ollama + Python: <https://ollama.com/blog/python-javascript-libraries>
- Fine-tuning local models: <https://ollama.com/blog/how-to-fine-tune>
- Optimizaci√≥n de prompts: <https://www.promptingguide.ai/>

---

## üöÄ C√≥mo Empezar AHORA

### Quick Start (5 minutos)

1. **Instala Ollama:**

   ```bash
   curl -fsSL https://ollama.com/install.sh | sh
   ollama pull llama3.2
   ```

2. **Ejecuta el script automatizado:**

   ```bash
   cd scripts
   ./run_ia.sh
   ```
   
   Este script hace todo por ti:
   - ‚úÖ Verifica/inicia Ollama
   - ‚úÖ Descarga el modelo si falta
   - ‚úÖ Instala dependencias Python
   - ‚úÖ Procesa 3 recetas en modo dry-run
   
3. **O usa el script Python directamente:**

   ```bash
   cd scripts
   
   # Test con 3 recetas (sin guardar)
   python ia_main.py --recipes 3 --dry-run
   
   # Procesar y guardar 10 recetas
   python ia_main.py --recipes 10
   ```

4. **Ver ayuda completa:**

   ```bash
   python ia_main.py --help
   ```

3. **Primer test con el servicio de IA:**

   Ver [`scripts/services/ai_service.py`](scripts/services/ai_service.py) para el servicio completo.

   ```python
   from services.ai_service import crear_servicio_ia
   
   # Crear servicio
   ai = crear_servicio_ia('llama3.2')
   
   # Verificar modelos disponibles
   print(ai.listar_modelos_disponibles())
   
   # Generar respuesta
   respuesta = ai.generar_respuesta("Sugiere 5 tags para una pasta carbonara")
   print(respuesta)
   ```

4. **Ejecutar scripts de procesamiento:**

   ```bash
   # Procesar recetas
   cd scripts
   python -m ai.process_recipes
   
   # Optimizar tags
   python -m ai.optimize_tags
   
   # Buscar recetas
   python -m ai.search_recipes
   ```

---

## üí° Notas Finales

### Privacidad y Ventajas

- ‚úÖ **100% Local:** Nada sale de tu computadora
- ‚úÖ **Sin Costos:** No hay APIs de pago ni suscripciones
- ‚úÖ **Personalizable:** Ajusta prompts a tus necesidades
- ‚úÖ **Escalable:** Funciona con 50 o 5000 recetas

### Limitaciones Conocidas

- ‚ö†Ô∏è Requiere GPU/RAM significativa para modelos grandes
- ‚ö†Ô∏è Procesamiento m√°s lento que APIs cloud (OpenAI, etc)
- ‚ö†Ô∏è Calidad depende del modelo y prompts
- ‚ö†Ô∏è Necesita ajustes y experimentaci√≥n inicial

### Pr√≥ximos Pasos Recomendados

1. **Ejecutar el script automatizado:** `./run_ia.sh`
2. **Probar con pocas recetas:** `python ia_main.py --recipes 3 --dry-run`
3. **Ajustar prompts seg√∫n resultados** en [`ia_main.py`](scripts/ia_main.py)
4. **Procesar dataset completo:** `python ia_main.py --recipes 50`
5. **Probar optimizaci√≥n de tags:** `python -m ai.optimize_tags`
6. **Probar b√∫squeda sem√°ntica:** `python -m ai.search_recipes`
7. **Integrar con frontend**
8. **Documentar aprendizajes**

**Scripts principales disponibles:**

- **‚≠ê [`ia_main.py`](scripts/ia_main.py)** - Script principal con CLI (recomendado)
- **‚≠ê [`run_ia.sh`](scripts/run_ia.sh)** - Script bash automatizado (m√°s f√°cil)
- [`scripts/ai/process_recipes.py`](scripts/ai/process_recipes.py) - M√≥dulo de procesamiento
- [`scripts/ai/optimize_tags.py`](scripts/ai/optimize_tags.py) - Optimizador de tags
- [`scripts/ai/search_recipes.py`](scripts/ai/search_recipes.py) - B√∫squeda sem√°ntica
- [`scripts/ai/analyze_posts.py`](scripts/ai/analyze_posts.py) - An√°lisis de posts
- [`scripts/services/ai_service.py`](scripts/services/ai_service.py) - Servicio compartido

---

**¬øListo para comenzar?** Consulta el [README principal](README.md) para entender el contexto del proyecto completo.

**¬øNecesitas ayuda?** Abre un issue en el repositorio o consulta la documentaci√≥n oficial de Ollama.
